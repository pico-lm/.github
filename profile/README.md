# Pico: The Framework for Language Model Learning Dynamics

Welcome to **Pico** ðŸ‘‹, a cutting-edge model suite and training framework designed to transform how language models are built and studied. By prioritizing **evidence-based design** over intuition-driven experimentation, Pico makes language model development more of a **science** than an **art**.

## What Is Pico?
Pico provides:
- A suite of **LLaMA-style models**, ready to use out of the box.
- A **comprehensive framework** for model training and analysis.
- A dataset of **420 billion tokens**, derived from a custom, pre-shuffled, and pre-tokenized version of the **OLMO dataset**.
- Consistent dataset, architecture, and training processesâ€”allowing parameter count to be the **only variable**, ensuring precise comparisons of learning behaviors across different model sizes.

## What Makes Pico Special?
Pico offers a **new level of transparency and interpretability** in model training:

- **Full Access to Training Checkpoints**: Every training step is available, allowing in-depth analysis of model development over time.
- **Advanced Gradient and Activation Data**: Enables post-hoc interpretability studies on key learning dynamics.
- **Detailed Learning Trajectories**: Study **convergence rates, induction head evolution, data memorization**, and more.
- **Pico-Analysis Toolkit**: Compute key metrics for **mechanistic interpretability** with ease.

Pico prioritizes **small-to-medium-scale models**, allowing for meaningful experimentation **without excessive computational costs**. The lightweight, **modular codebase** is easy to **fork, extend, and adapt** for a variety of research applications.

## Open-Source Commitment
Pico is built on an **open-source ethos**:
- **All code, checkpoints, and datasets** are publicly available.
- Designed for researchers, educators, and developers to **collaborate, experiment, and innovate** freely.

### Get Involved
- Visit our website: [https://picolm.io](https://picolm.io)
- Explore our repositories and contribute!
- Contact us for funding opportunities and collaborations.

**Join us in redefining how language models are built, analyzed, and understood.**

